{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using MLP Classifier\n",
    "Resources:<br>\n",
    "https://analyticsindiamag.com/a-beginners-guide-to-scikit-learns-mlpclassifier/<br>\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html<br>\n",
    "<br>\n",
    "\n",
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data sets and create validation set (15% of training set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./../dataset/csv/mnist_train.csv\", header=None)\n",
    "\n",
    "size_data = len(data)\n",
    "data = data.sample(size_data)\n",
    "limit = math.floor(3*size_data/20)\n",
    "\n",
    "validation_data = data[:limit]\n",
    "train_data = data[limit:]\n",
    "\n",
    "test_data = pd.read_csv(\"./../dataset/csv/mnist_test.csv\", header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create sparse matrix of shape and classification for train, validation and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The division by 255 transforms integers in floats to have a better percision\n",
    "train_sparse_matrix = train_data.iloc[:,1:].values/255\n",
    "train_sparse_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_classes = train_data.iloc[:,0:1].values.ravel()\n",
    "train_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_sparse_matrix = validation_data.iloc[:,1:].values/255\n",
    "validation_classes = validation_data.iloc[:,0:1].values.ravel()\n",
    "\n",
    "test_sparse_matrix = test_data.iloc[:,1:].values/255\n",
    "test_classes = test_data.iloc[:,0:1].values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use MLP Classifier\n",
    "### Define functions for accuracy and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(confusion_matrix):\n",
    "    diagonal_sum = confusion_matrix.trace()\n",
    "    sum_of_all_elements = confusion_matrix.sum()\n",
    "    \n",
    "    return diagonal_sum / sum_of_all_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For the loss of the classifier, we use the cross-entropy\n",
    "# def loss_function(data_pred, data_classes):\n",
    "#     loss = 0\n",
    "# #     for i in range(len(data_classes)):\n",
    "# #         if (data_pred[i] != data_classes[i]):\n",
    "# #             loss += 1\n",
    "# #     loss = loss/len(data_classes)\n",
    "\n",
    "# #     print(data_classes)\n",
    "# #     print(np.log(data_pred))\n",
    "\n",
    "# #     print(np.dot(data_classes, np.log(data_pred)))\n",
    "    \n",
    "#     temp = 0\n",
    "#     for i in range(len(data_classes)):\n",
    "#         print(\"data_classes[i]: {}\".format(data_classes[i]))\n",
    "#         print(\"data_pred[i]: {}\".format(data_pred[i]))\n",
    "#         print(\"log data_pred[i]: {}\".format(np.log(data_pred)[i]))\n",
    "#         print(\"product: {}\".format(data_classes[i]*np.log(data_pred)[i]))\n",
    "        \n",
    "#         temp += data_classes[i]*np.log(data_pred)[i]\n",
    "#         print(temp)\n",
    "#         print()\n",
    "    \n",
    "#     loss = -np.dot(data_classes, np.log(data_pred))\n",
    "    \n",
    "#     return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to initialize and optimize classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_classifier(num_hl, learning_rate, max_iter):\n",
    "    return MLPClassifier(hidden_layer_sizes=(num_hl), max_iter=max_iter, activation = 'relu', solver='adam', learning_rate='constant', learning_rate_init=learning_rate, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification(max_iter, nhl, lr): \n",
    "    \n",
    "    classification_results = pd.DataFrame(columns=['nhl', 'lr', 'acc_valid', 'loss_valid', 'acc_train', 'loss_train'])\n",
    "    \n",
    "    classifier = create_classifier(nhl, lr, max_iter) \n",
    "    \n",
    "#   Training network\n",
    "    classifier.fit(train_sparse_matrix, train_classes)\n",
    "\n",
    "#             Validation set\n",
    "    validation_pred = classifier.predict(validation_sparse_matrix)\n",
    "    \n",
    "    cm_valid = confusion_matrix(validation_pred, validation_classes)            \n",
    "    acc_valid = accuracy(cm_valid)\n",
    "    print(\"Accuracy valid: {}\".format(acc_valid))\n",
    "    \n",
    "    print(\"Loss: {}\".format(classifier.loss_))\n",
    "    loss_valid = classifier.loss_\n",
    "#     loss_valid = loss_function(validation_pred, validation_classes)\n",
    "\n",
    "\n",
    "\n",
    "#             Training set\n",
    "    train_pred = classifier.predict(train_sparse_matrix)\n",
    "    \n",
    "    cm_train = confusion_matrix(train_pred, train_classes)\n",
    "    acc_train = accuracy(cm_train)\n",
    "    print(\"\\nAccuracy train: {}\".format(acc_train))\n",
    "    \n",
    "    print(\"Loss: {}\\n-----\\n\".format(classifier.loss_))\n",
    "#     loss_train = loss_function(train_pred, train_classes)\n",
    "    loss_train = classifier.loss_\n",
    "\n",
    "    classification_results.loc[len(classification_results)] = [nhl, lr, acc_valid, loss_valid, acc_train, loss_train]\n",
    "\n",
    "    return classification_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_test(max_iter, nhl, lr): \n",
    "    \n",
    "    classification_results = pd.DataFrame(columns=['nhl', 'lr', 'acc', 'loss'])\n",
    "    \n",
    "    classifier = create_classifier(nhl, lr, max_iter) \n",
    "#   Learning\n",
    "    classifier.fit(train_sparse_matrix, train_classes)\n",
    "\n",
    "#             Test set\n",
    "    test_pred = classifier.predict(test_sparse_matrix)\n",
    "    cm = confusion_matrix(test_pred, test_classes)            \n",
    "    acc = accuracy(cm)\n",
    "    loss = loss_function(test_pred, test_classes)\n",
    "\n",
    "    classification_results.loc[len(classification_results)] = [nhl, lr, acc, loss]\n",
    "\n",
    "    return classification_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different number Hidden Layers and Learning rates to find the best classifier\n",
    "nhl_range = [10, 50, 100]\n",
    "learning_rates = [0.1, 0.01, 0.001]\n",
    "\n",
    "# We loop over the different parameters\n",
    "for nhl in nhl_range:\n",
    "        for lr in learning_rates:\n",
    "#             Table containing the results\n",
    "            classification_epoch = pd.DataFrame(columns=['iter', 'acc_valid', 'loss_valid', 'acc_train', 'loss_train'])\n",
    "                        \n",
    "            for m in range (1,6):\n",
    "                acc_loss_m = classification(m, nhl, lr)\n",
    "                classification_epoch.loc[len(classification_epoch)] = [m, acc_loss_m['acc_valid'][0], acc_loss_m['loss_valid'][0], acc_loss_m['acc_train'][0], acc_loss_m['loss_train'][0]]\n",
    "    \n",
    "            print(\"\\nNumber neurons in hidden layer: {}\".format(nhl))\n",
    "            print(\"learning rate: {}\\n\".format(lr))\n",
    "            print(classification_epoch)\n",
    "\n",
    "            plt.subplot(2,1,1)\n",
    "            plt.title(\"Accuracy and Loss\")\n",
    "            plt.xlabel(\"Epochs\")\n",
    "            plt.ylabel(\"Accuracy (in %)\")\n",
    "            plt.plot(classification_epoch['iter'], classification_epoch['acc_valid'], \"-b\", label='Validation')\n",
    "            plt.plot(classification_epoch['iter'], classification_epoch['acc_train'], \"-r\", label='Training')\n",
    "            plt.legend()\n",
    "\n",
    "            plt.subplot(2,1,2)\n",
    "            plt.xlabel(\"Epochs\")\n",
    "            plt.ylabel(\"Loss\")\n",
    "            plt.plot(classification_epoch['iter'], classification_epoch['loss_valid'], \"-b\", label='Validation')\n",
    "            plt.plot(classification_epoch['iter'], classification_epoch['loss_train'], \"-r\", label='Training')\n",
    "            plt.legend()\n",
    "\n",
    "            plt.show()\n",
    "            print(\"\\n------------------------------------------------------\\n\")\n",
    "\n",
    "            \n",
    "# classification_test(optimal_iter, optimal_nhl, optimal_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this validation phase, when we look at the previous tests, we clearly see that the best learning rate is 0.001 (the bigger ones give completely divergent accuracy).<br>\n",
    "For the number of neurons in the hidden layer, the best choice is 100.<br>\n",
    "<br>\n",
    "Now we want to to the MLP classification with the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_nhl = 100\n",
    "optimal_learning_rate = 0.001\n",
    "max_iter = 15\n",
    "\n",
    "classification_epoch = pd.DataFrame(columns=['iter', 'acc', 'loss'])\n",
    "acc_loss_m = classification_test(max_iter, optimal_nhl, optimal_learning_rate)\n",
    "classification_epoch.loc[len(classification_epoch)] = [max_iter, acc_loss_m['acc'][0], acc_loss_m['loss'][0]]\n",
    "\n",
    "final_accuracy = classification_epoch['acc'][0]*100\n",
    "\n",
    "print(\"Accuracy of MLP classifier with optimized parameter values: %.3f\" % final_accuracy, '%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
