{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Team Task (Permutated MNIST)\n",
    "## LoÃ¯c Rosset, Nanae Aubry, Kilian Ruchti, Lionel Ieri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import module\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "from copy import deepcopy\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from model_task2c import PR_CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "TRAIN_DATASET = \"../dataset/png/mnist_permutated/train\"\n",
    "VALIDATION_DATASET = \"../dataset/png/mnist_permutated/val\"\n",
    "TEST_DATASET = \"../dataset/png/mnist_permutated/test\"\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root=TRAIN_DATASET, transform=transform)\n",
    "val_dataset = datasets.ImageFolder(root=VALIDATION_DATASET, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root=TEST_DATASET, transform=transform)\n",
    "\n",
    "params = {'batch_size': 64, 'shuffle': True}\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, **params)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, **params)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, **params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(nb_epochs, train, val, step):\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(nb_epochs), train)\n",
    "    plt.plot(np.arange(nb_epochs), val)\n",
    "    plt.legend(['training', 'validation'])\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel(f'{step} value')\n",
    "    plt.title(f'Train/val {step}');\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Training():\n",
    "    \n",
    "    def __init__(self, nb_epochs=20, device=torch.device('cpu')):\n",
    "        self.nb_epochs = nb_epochs\n",
    "        self.device = device\n",
    "    \n",
    "    def train(self, model, train_loader, optimizer, loss_func):\n",
    "        model.train()\n",
    "        \n",
    "        losses = []\n",
    "        correct_train_pred = 0\n",
    "        \n",
    "        for data, labels in train_loader:\n",
    "            data = data.to(self.device)\n",
    "            labels = labels.to(self.device)\n",
    "            \n",
    "            # Predict the classes of the model\n",
    "            output = model(data)\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Compute the loss\n",
    "            loss = loss_func(output, labels)\n",
    "            \n",
    "            # Perform backprop\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Save current loss\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "            # Save the number of correct classified items\n",
    "            predicted_labels = output.argmax(dim=1)\n",
    "            nb_correct = (predicted_labels == labels).sum().item()\n",
    "            correct_train_pred += nb_correct\n",
    "    \n",
    "        train_accuracy = 100. * (correct_train_pred / len(train_loader.dataset))\n",
    "        \n",
    "        return np.mean(np.array(losses)), train_accuracy\n",
    "    \n",
    "    def validation(self, model, val_loader, loss_func):\n",
    "        model.eval()\n",
    "        \n",
    "        losses = []\n",
    "        correct_val_predictions = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data, labels in val_loader:\n",
    "                data = data.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "                \n",
    "                output = model(data)\n",
    "                \n",
    "                loss = loss_func(output, labels)\n",
    "                \n",
    "                # Save current loss\n",
    "                losses.append(loss.item())\n",
    "    \n",
    "                # Save the number of correct classified items\n",
    "                predicted_labels = output.argmax(dim=1)\n",
    "                n_correct = (predicted_labels == labels).sum().item()\n",
    "                correct_val_predictions += n_correct\n",
    "                \n",
    "        val_accuracy = 100. * (correct_val_predictions / len(val_loader.dataset))\n",
    "                \n",
    "        return np.mean(np.array(losses)), val_accuracy\n",
    "\n",
    "    def _print_info(self, train_loss, val_loss, train_acc, val_acc):\n",
    "        print(f'Train_loss: {train_loss:.3f} |\\\n",
    "                Val_loss: {val_loss:.3f} |\\\n",
    "                Train_acc: {train_acc:.3f} |\\\n",
    "                Val_acc: {val_acc:.3f}')\n",
    "\n",
    "    def fit(self, model, train_loader, val_loader, optimizer, loss_func):\n",
    "        train_losses, val_losses = [], []\n",
    "        train_accuracies, val_accuracies = [], []\n",
    "\n",
    "        for epoch in range(self.nb_epochs):\n",
    "            train_loss, train_acc = self.train(model, train_loader, optimizer, loss_func)\n",
    "            val_loss, val_acc = self.validation(model, val_loader, loss_func)\n",
    "\n",
    "            train_losses.append(train_loss)\n",
    "            train_accuracies.append(train_acc)\n",
    "            val_losses.append(val_loss)\n",
    "            val_accuracies.append(val_acc)\n",
    "\n",
    "        self._print_info(train_losses[-1], val_losses[-1], train_accuracies[-1], val_accuracies[-1])\n",
    "\n",
    "        return train_losses, val_losses, train_accuracies, val_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "l_rate_set = [0.001, 0.01, 0.1]\n",
    "nb_epochs = 5\n",
    "trainer = Training(nb_epochs)\n",
    "\n",
    "# best parameters: (validation acc, learning rate)\n",
    "best_parameters = (float(\"-INF\"), None, None)\n",
    "# keep a copy of the best trained network\n",
    "best_model = None\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "for l_rate in l_rate_set:\n",
    "    cnn = PR_CNN()\n",
    "    optimizer = torch.optim.SGD(cnn.parameters(), l_rate)\n",
    "    \n",
    "    # The training take place here :\n",
    "    print(f'learning rate: {l_rate}')\n",
    "    stats_training = trainer.fit(cnn, train_loader, val_loader, optimizer, loss_function)\n",
    "    \n",
    "    if stats_training[3][-1] > best_parameters[0]:\n",
    "        best_parameters = (stats_training[3][-1], l_rate, stats_training)\n",
    "        best_model = deepcopy(cnn)\n",
    "\n",
    "best_acc, best_l_rate, best_stats = best_parameters\n",
    "train_losses, val_losses, train_accuracies, val_accuracies = best_stats\n",
    "\n",
    "print(f'\\n\\nBest parameters: {best_l_rate} learning_rate and validation accuracies: {best_acc:.2f}%')\n",
    "\n",
    "plot_graph(nb_epochs, train_losses, val_losses, \"Loss\")\n",
    "plot_graph(nb_epochs, train_accuracies, val_accuracies, \"Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_test, acc_test = trainer.validation(best_model, test_loader, loss_function)\n",
    "print(f'Accuracy on the test dataset {acc_test:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Comparison with normal MNIST (results from 2b and 2c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
